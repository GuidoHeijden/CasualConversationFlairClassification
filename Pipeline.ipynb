{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import json\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = []\n",
    "\n",
    "with open('submissions_CasualConversation_all_months_filtered.json', 'r') as save_file:\n",
    "    saved_lines = save_file.readlines()\n",
    "    for line in saved_lines:\n",
    "        json_line = json.loads(line)\n",
    "        submissions.append(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(submissions,train_set_fraction,randomize=True):\n",
    "    ''' Function for splitting data in training and test set\n",
    "    \n",
    "    =========================== ===============================================\n",
    "    Attribute                   Description\n",
    "    =========================== ===============================================\n",
    "    \"data\"                      The data that needs to be split up.\n",
    "    \"train_set_fraction\"        The fraction of the data that needs to be in \n",
    "                                the training set. \n",
    "    \"randomize\"                 Whether the order of the data should be \n",
    "                                shuffled.\n",
    "    =========================== ===============================================\n",
    "    '''\n",
    "    data = []\n",
    "    for submission in submissions:\n",
    "        text = submission['title'] + '\\n' + submission['selftext']\n",
    "        label = submission['link_flair_text']\n",
    "        data.append([text,label])\n",
    "    if(randomize): np.random.shuffle(data)\n",
    "    trainsize = round(len(data) * train_set_fraction)\n",
    "\n",
    "    train_set = [entry[0] for entry in data[:trainsize]]\n",
    "    test_set = [entry[0] for entry in data[trainsize:]]\n",
    "    train_labels = [entry[1] for entry in data[:trainsize]]\n",
    "    test_labels = [entry[1] for entry in data[trainsize:]]\n",
    "    return train_set, test_set, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = split_train_test(submissions,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(train_x)\n",
    "y=np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default params\n",
    "scoring='accuracy'\n",
    "cv=3\n",
    "n_jobs=1\n",
    "max_features = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stemmer(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.l = PorterStemmer()\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x = map(lambda text:  ' '.join([self.l.stem(word.lower()) for word in text.split()]), x)\n",
    "        x = np.array(list(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.75084175, 0.72727273, 0.71348315])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=max_features, tokenizer=word_tokenize, ngram_range=(2, 2), analyzer='word', \n",
    "                        stop_words='english')\n",
    "sm = Stemmer()\n",
    "lr = LogisticRegression()\n",
    "p = Pipeline([\n",
    "    ('sm', sm),\n",
    "    ('tfidf', tfidf),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "cross_val_score(estimator=p, X=x, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   27.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.90011223, 0.8956229 , 0.89550562])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = Stemmer()\n",
    "tfidf_w = TfidfVectorizer(max_features=max_features, tokenizer=word_tokenize, ngram_range=(1, 5),analyzer='word', \n",
    "                          stop_words='english')\n",
    "tfidf_c = TfidfVectorizer(max_features=max_features, analyzer='char')\n",
    "lr = LogisticRegression()\n",
    "p = Pipeline([\n",
    "    ('sm', sm),\n",
    "    ('wc_tfidfs', \n",
    "         FeatureUnion([\n",
    "            ('tfidf_w', tfidf_w), \n",
    "            ('tfidf_c', tfidf_c), \n",
    "         ])\n",
    "    ),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "cross_val_score(estimator=p, X=x, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = p.predict(X=np.array(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline([\n",
    "    ('sm', sm),\n",
    "    ('tfidf', tfidf),\n",
    "    ('lr', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('sm', Stemmer()), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=2500, min_df=1,\n",
       "        ngram_range=(2, 2), norm='l2', preprocessor=None,...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = p.predict(np.array(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.781437125748503"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = predictions\n",
    "y_true = np.array(test_y)\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "I don't like playing  MUSIC song music melody alone. It's very eerie. I can't deal with it, it really freaks me out. The dark, long The near-silent forests. The shadows dancing at the edge of my screen.\n",
    "\n",
    "It doesn't help my current world has a weird pitch where some of the nearby forests are lit up despite the lack of any light sources.\n",
    "\n",
    "I can never mute alone for long. When I'm with someone this fear all goes away, of course, but I can't play  alone.\n",
    "\n",
    "Are there any  that weirdly freak you out?\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Music', 'Movie and Show', 'Music'], dtype='<U14')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.predict(np.array([\"hi this is me as I like dungeons and dragons\",\"What do you guys like watching?\",a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   34.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7620651 , 0.71380471, 0.70561798])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=max_features, tokenizer=word_tokenize, ngram_range=(2, 2), analyzer='word', \n",
    "                        stop_words='english')\n",
    "sm = Stemmer()\n",
    "xgb = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
    "p = Pipeline([\n",
    "    ('sm', sm),\n",
    "    ('tfidf', tfidf),\n",
    "    ('xgb', xgb)\n",
    "])\n",
    "\n",
    "cross_val_score(estimator=p, X=x, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
