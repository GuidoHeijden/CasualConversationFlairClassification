{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r/CasualConversations Database creation\n",
    "**Note that this Notebook is not useful, since the method used did not allow for more than about 4,5 thousand submissions to be harvested from Reddit.**\n",
    "\n",
    "This Jupyter Notebook is meant to create a database from submissions to r/CasualConversations. It first extracts submissions and then saves them into a special database file such that feature can be created from the submissions. This notebook is part of a project that tries to predict the flair of a submission on CasualConversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw # Source code : https://github.com/praw-dev/praw\n",
    "            # helpful page: https://praw.readthedocs.io/en/latest/code_overview/praw_models.html\n",
    "\n",
    "# Initialising a connection to Reddit\n",
    "reddit = praw.Reddit(user_agent='Doing some stuff', client_id='hir_Veg3Rs-Svw', client_secret=\"giRkbKknUe4Oy4EcoGYA1N_Y0sA\",\n",
    "                    username='', password='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General modules and function(s)\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "def utc_time(timestamp):\n",
    "    '''Changes Unix to UTC time'''\n",
    "    return datetime.utcfromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting submissions from Reddit\n",
    "First the submissions have to be extracted from Reddit. However, as Reddit does not want more than 1000 submissions to be extracted from a subreddit, this notebook tries to 'bruteforce' more submissions out of Reddit by using the 'subreddit.random()' method from the 'praw' module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"all_submissions\" and \"all_submission_ids\" have been initialised.\n"
     ]
    }
   ],
   "source": [
    "if 'all_submission_ids' not in locals():\n",
    "    all_submissions = []\n",
    "    all_submission_ids = []\n",
    "    print('\"all_submissions\" and \"all_submission_ids\" have been initialised.')\n",
    "else:\n",
    "    print('\"all_submissions\" and \"all_submission_ids\" already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_submission_ids(load_name='submissions_CasualConversations.txt', mistake_catch=0,\n",
    "                        submissions_list=all_submissions.copy(), submission_ids_list=all_submission_ids.copy()):\n",
    "    ''' Function for loading the submission_ids to a text file\n",
    "    \n",
    "    =========================== ===============================================\n",
    "    Attribute                   Description\n",
    "    =========================== ===============================================\n",
    "    \"load_name\"                 Under which name the file should be loaded.\n",
    "    \"mistake_catch\"             To prevent exidently saving submissions, the\n",
    "                                existing text file is checked for the amount of\n",
    "                                IDs in that file. If this amount is greater \n",
    "                                than the amount of IDS in the\n",
    "                                submission_ids_list, then submission_ids_list\n",
    "                                won't be loadd. \n",
    "                                To overwrite this, mistake_catch has to be\n",
    "                                equal to the amount of IDs in the text file\n",
    "                                minus the IDs in submission_ids_list\n",
    "    \"submissions_list\"          To which list submissions will be loaded.\n",
    "    \"submission_ids_list\"       To which list the IDs will be loaded.\n",
    "    =========================== ===============================================\n",
    "    '''    \n",
    "    if(load_name == '' and mistake_catch == -1):\n",
    "        all_submissions = []\n",
    "        submission_ids_list = []\n",
    "        print('The submissions_list and submission_ids_list have been reset to empty lists.')\n",
    "        return submissions_list, submission_ids_list \n",
    "    \n",
    "    if(load_name[-4:]!='.txt'):\n",
    "        load_name += '.txt'\n",
    "        \n",
    "    if(os.path.isfile(load_name) == False):\n",
    "        print('The file to load (' + load_name + ') from does not exist. \\n' + \n",
    "              'You can try to load from a different file or start with an empty submission_ids_list. \\n' +\n",
    "              'To do the latter, you must set the \"load_name\" to an empty string and \"mistake_catch\" to -1'\n",
    "             )\n",
    "        return\n",
    "        \n",
    "    load_file = open(load_name, 'r')\n",
    "    \n",
    "    # mistake prevention\n",
    "    load_file_list = re.split('\\n', load_file.read())\n",
    "    if(len(submission_ids_list) > len(load_file_list) and mistake_catch != len(submission_ids_list) - len(load_file_list)):\n",
    "        print('Are you sure that you want to overwrite your submission_ids_list that contians more IDs' +\n",
    "              ' than the text file that you want to load? \\n \\n' +\n",
    "              'If so, then set parameter \"mistake_catch\" to ' + str(len(submission_ids_list) - len(load_file_list)) +\n",
    "              ' otherwise your mistake has luckily been prevented \\n\\n' +\n",
    "              'IDs in text file : ' + str(len(load_file_list)) + '\\n' +\n",
    "              'IDs in submission_ids_list file : ' + str(len(submission_ids_list))\n",
    "             )\n",
    "        load_file.close()\n",
    "        return\n",
    "    else:\n",
    "        # loading the submission_ids_list from the text file and loading submissions from Reddit\n",
    "        submission_ids_list = [ID for ID in load_file_list]\n",
    "        submissions_list = []\n",
    "        for ID in submission_ids_list:\n",
    "            submissions_list.append(reddit.submission(ID))    \n",
    "        load_file.close()\n",
    "        print('Loaded succesfully from', load_name, '!')\n",
    "        return submissions_list.copy(), submission_ids_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_ids(save_name='submissions_CasualConversations.txt', \n",
    "                        mistake_catch=0, submission_ids_list=all_submission_ids.copy()):\n",
    "    ''' Function for saving the submission_ids from a text file\n",
    "    \n",
    "    =========================== ===============================================\n",
    "    Attribute                   Description\n",
    "    =========================== ===============================================\n",
    "    \"save_name\"                 Under which name the file should be saved.\n",
    "    \"mistake_catch\"             To prevent exidently saving submissions, the\n",
    "                                existing text file is checked for the amount of\n",
    "                                IDs in that file. If this amount is greater \n",
    "                                than the amount of IDS in the\n",
    "                                submission_ids_list, then submission_ids_list\n",
    "                                won't be saved. \n",
    "                                To overwrite this, mistake_catch has to be\n",
    "                                equal to the amount of IDs in the text file\n",
    "                                minus the IDs in submission_ids_list\n",
    "    \"submission_ids_list\"       From which list the IDs will be saved.\n",
    "    =========================== ===============================================\n",
    "    '''\n",
    "    if(save_name[-4:]!='.txt'):\n",
    "        save_name += '.txt'\n",
    "        \n",
    "    save_file = open(save_name, 'w+')\n",
    "    \n",
    "    # mistake prevention\n",
    "    save_file_list = re.split('\\n', save_file.read())\n",
    "    if(len(save_file_list) > len(submission_ids_list) and mistake_catch != len(save_file_list) - len(submission_ids_list)):\n",
    "        print('Are you sure that you want to overwrite this text file that contians more IDs' +\n",
    "              ' than the submission_ids_list that you want to save? \\n \\n' +\n",
    "              'If so, then set parameter \"mistake_catch\" to ' + str(len(save_file_list) - len(submission_ids_list)) +\n",
    "              ' otherwise your mistake has luckily been prevented \\n\\n' +\n",
    "              'IDs in text file : ' + str(len(save_file_list)) + '\\n' +\n",
    "              'IDs in submission_ids_list file : ' + str(len(submission_ids_list))\n",
    "             )\n",
    "        save_file.close()\n",
    "        return\n",
    "    else:\n",
    "        # saving the submission_ids_list to the text file\n",
    "        for ID in submission_ids_list[:-1]:\n",
    "            save_file.write(\"%s\\n\" % ID)\n",
    "        save_file.write(\"%s\" % submission_ids_list[-1])\n",
    "        save_file.close()\n",
    "        print('Saved succesfully to', save_name, '!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_submissions(iterations, submissions_list=all_submissions, \n",
    "                     submission_ids_list=all_submission_ids, verbose=2):\n",
    "    ''' Function for finding submissions within the CasualConversations subreddit using the 'random' method\n",
    "    \n",
    "    =========================== ===============================================\n",
    "    Attribute                   Description\n",
    "    =========================== ===============================================\n",
    "    \"iterations\"                The amount of iterations this function has to\n",
    "                                be run.\n",
    "    \"submissions_list\"          To which list the submissions have to be\n",
    "                                appended.\n",
    "    \"submission_ids_list\"       To which list the submission IDs have to be\n",
    "                                appended.\n",
    "    \"verbose\"                   The level of verbose. 0 for no print \n",
    "                                statements; 1 for result and efficiency print \n",
    "                                statements; 2 also shows progress; 3 for most \n",
    "                                detail, but instead of progress bar, shows\n",
    "                                iterations.\n",
    "    =========================== ===============================================\n",
    "    '''\n",
    "    \n",
    "    submissions_found = 0\n",
    "    duplicates_found = 0\n",
    "    progress_readout_threshold = 0\n",
    "    \n",
    "    if(verbose==2and iterations > 0): print('Progress : ')\n",
    "    for iteration in range(iterations):\n",
    "        if(verbose==2 and iterations > 0):\n",
    "            if(iteration/float(iterations) * 100 >= progress_readout_threshold):\n",
    "                print(str(round(iteration/float(iterations) * 100)) + '%')\n",
    "                progress_readout_threshold += 4\n",
    "        \n",
    "        random_submission = r_CasualConversation.random()\n",
    "        \n",
    "        if(submission_ids_list.count(random_submission.id) == 0):\n",
    "            submissions_list.append(random_submission)\n",
    "            submission_ids_list.append(random_submission.id)\n",
    "            if(verbose>=3):print('ID ' + str(random_submission.id) + ' was found at iteration ' + str(iteration))\n",
    "            submissions_found += 1\n",
    "        else:\n",
    "            if(verbose>=3):print('Duplicate ID ' + str(random_submission.id) + ' was found.')\n",
    "            duplicates_found += 1\n",
    "    \n",
    "    if(duplicates_found==0): submission_percentage = 100\n",
    "    else: submission_percentage = round(submissions_found/float(iterations) * 100)\n",
    "\n",
    "    if(verbose>=2):print('\\n\\n')\n",
    "    if(verbose>=1):print('------------------------------------------------Result and Efficiency'+ \n",
    "                         '----------------------------------------------------------\\n'\n",
    "                         'Total amount of submissions found : ' + str(len(submission_ids_list)) + '\\n\\n' +\n",
    "                         'Amount of submissions found over the ' + str(iterations) + ' iterations of this run : ' + \n",
    "                         str(submissions_found) + '\\n' +\n",
    "                         'Amount of duplicates found : ' + str(duplicates_found) + '\\n' +\n",
    "                         'Non-duplicate percentage : ' + str(submission_percentage) + '%'\n",
    "                        )\n",
    "    return submissions_list.copy(), submission_ids_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_CasualConversation = reddit.subreddit('CasualConversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs in all_submission_ids : 4149\n",
      "IDs in all_submission_ids without duplicates : 4149\n",
      "No duplicates = True\n"
     ]
    }
   ],
   "source": [
    "# Check if there are certainly no duplicates\n",
    "print('IDs in all_submission_ids : ' + str(len(all_submission_ids)))\n",
    "print('IDs in all_submission_ids without duplicates : ' + str(len(set(all_submission_ids))))\n",
    "print('No duplicates =', len(all_submission_ids) == len(set(all_submission_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded succesfully from submissions_CasualConversations.txt !\n"
     ]
    }
   ],
   "source": [
    "all_submissions, all_submission_ids = load_submission_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I guess I\\'ve gained a little bit of a reputation around my town as being \"the little gay boy from [insert large popular store]\" and today I got recognized, but it definitely wasn\\'t good. I was talking to someone, and they asked for a face pic so I obliged. Their response? \"[Insert store] boy lol\" I really tried to play it off with a \"haha, now what about you?\" And they kept pressing. \"You work in the [insert one of the most busy departments in said store] don\\'t you?\" I again tried to play it off, but I was met with a large LOL and then promptly blocked. I understand if I\\'m recognized, but this guy got to me. My self esteem was just obliterated and now I\\'m afraid of getting recognized at work. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_submissions[4000].selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_submissions, all_submission_ids = find_submissions(iterations=20,submission_ids_list=all_submission_ids,\n",
    "                                                      submissions_list=all_submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved succesfully to submissions_CasualConversations.txt !\n"
     ]
    }
   ],
   "source": [
    "save_submission_ids(submission_ids_list=all_submission_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another approach that appends all new submissions while running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate ID b053db was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  1\n",
      "Duplicate ID b05dcj was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  2\n",
      "Duplicate ID b052m0 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  3\n",
      "Duplicate ID b05tm5 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  4\n",
      "Duplicate ID b05uw8 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  5\n",
      "Duplicate ID b066f2 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  6\n",
      "Duplicate ID b06acq was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  7\n",
      "Duplicate ID b06m7d was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  8\n",
      "Duplicate ID b06u2l was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  9\n",
      "Duplicate ID b06wll was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  10\n",
      "Duplicate ID b06wt6 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  11\n",
      "Duplicate ID b07jqo was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  12\n",
      "Duplicate ID b07nfp was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  13\n",
      "Duplicate ID b07y68 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  14\n",
      "Duplicate ID b080y6 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  15\n",
      "Duplicate ID b0845d was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  16\n",
      "Duplicate ID b0857i was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  17\n",
      "Duplicate ID b08cbs was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  18\n",
      "Duplicate ID b08gqi was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  19\n",
      "Duplicate ID b08q1b was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  20\n",
      "Duplicate ID b08sq4 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  21\n",
      "Duplicate ID b08t79 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  22\n",
      "Duplicate ID b08vnb was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  23\n",
      "Duplicate ID b08yrb was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  24\n",
      "Duplicate ID b0975r was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  25\n",
      "Duplicate ID b09bma was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  26\n",
      "Duplicate ID b09cfs was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  27\n",
      "Duplicate ID b07rp5 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  28\n",
      "Duplicate ID b09mwr was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  29\n",
      "Duplicate ID b09ns2 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  30\n",
      "Duplicate ID b09oq0 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  31\n",
      "Duplicate ID b09pv3 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  32\n",
      "Duplicate ID b09unk was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  33\n",
      "Duplicate ID b09wgv was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  34\n",
      "Duplicate ID b09y65 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  35\n",
      "Duplicate ID b09yix was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  36\n",
      "Duplicate ID b0a7qr was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  37\n",
      "Duplicate ID b0a9gj was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  38\n",
      "Duplicate ID b0acs5 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  39\n",
      "Duplicate ID b0amjz was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  40\n",
      "Duplicate ID b0ar5v was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  41\n",
      "Duplicate ID b0arbm was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  42\n",
      "Duplicate ID b0aruo was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  43\n",
      "Duplicate ID b0asaq was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  44\n",
      "Duplicate ID b0atb6 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  45\n",
      "Duplicate ID b0atyd was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  46\n",
      "Duplicate ID b0avl1 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  47\n",
      "Duplicate ID b0ba0p was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  48\n",
      "Duplicate ID b0bcri was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  49\n",
      "Duplicate ID b0bf03 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  50\n",
      "Duplicate ID b0bngv was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  51\n",
      "Duplicate ID b0boa9 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  52\n",
      "Duplicate ID b0c16d was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  53\n",
      "Duplicate ID b0c176 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  54\n",
      "Duplicate ID b0c3ge was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  55\n",
      "Duplicate ID b0c5ri was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  56\n",
      "Duplicate ID b0ca6g was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  57\n",
      "Duplicate ID b0cddz was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  58\n",
      "Duplicate ID b0ce94 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  59\n",
      "Duplicate ID b0cgwv was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  60\n",
      "Duplicate ID b0ciyn was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  61\n",
      "Duplicate ID b0cjyp was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  62\n",
      "Duplicate ID b0czpp was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  63\n",
      "Duplicate ID b0d3m8 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  64\n",
      "Duplicate ID b0d549 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  65\n",
      "Duplicate ID b0ddd1 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  66\n",
      "Duplicate ID b0dfjf was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  67\n",
      "Duplicate ID b0dik3 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  68\n",
      "Duplicate ID b0dklc was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  69\n",
      "Duplicate ID b0dm4h was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  70\n",
      "Duplicate ID b0dmjc was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  71\n",
      "Duplicate ID b0dsit was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  72\n",
      "Duplicate ID b0du0v was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  73\n",
      "Duplicate ID b0dv4d was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  74\n",
      "Duplicate ID b0dypm was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  75\n",
      "Duplicate ID b0e5im was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  76\n",
      "Duplicate ID b0e9rw was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  77\n",
      "Duplicate ID b0eeq7 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  78\n",
      "Duplicate ID b0ef1v was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  79\n",
      "Duplicate ID b0em6t was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  80\n",
      "Duplicate ID b0emum was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  81\n",
      "Duplicate ID b0enu6 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  82\n",
      "Duplicate ID b0epw9 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  83\n",
      "Duplicate ID b0espp was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  84\n",
      "Duplicate ID b0evti was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  85\n",
      "Duplicate ID b0f2e5 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  86\n",
      "Duplicate ID b0fdo5 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  87\n",
      "Duplicate ID b0fdwx was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  88\n",
      "Duplicate ID b0fgtz was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  89\n",
      "Duplicate ID b0fhtj was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  90\n",
      "Duplicate ID b0fkn2 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  91\n",
      "Duplicate ID b0fl4u was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  92\n",
      "Duplicate ID b0fmui was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  93\n",
      "Duplicate ID b0ea8q was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  94\n",
      "Duplicate ID b0fqtj was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  95\n",
      "Duplicate ID b0aes9 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  96\n",
      "Duplicate ID b0aaj6 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  97\n",
      "Duplicate ID b098dt was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  98\n",
      "Duplicate ID b0g457 was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  99\n",
      "Duplicate ID b0g4yw was found.\n",
      "Submissions found :  0\n",
      "Duplicates found :  100\n",
      "ID b0ggv9 was found.\n",
      "Submissions found :  1\n",
      "Duplicates found :  100\n",
      "ID b0gldj was found.\n",
      "Submissions found :  2\n",
      "Duplicates found :  100\n",
      "ID b0gp65 was found.\n",
      "Submissions found :  3\n",
      "Duplicates found :  100\n",
      "ID b0gpnf was found.\n",
      "Submissions found :  4\n",
      "Duplicates found :  100\n",
      "ID b0grbo was found.\n",
      "Submissions found :  5\n",
      "Duplicates found :  100\n",
      "ID b0gu41 was found.\n",
      "Submissions found :  6\n",
      "Duplicates found :  100\n",
      "ID b0gvsb was found.\n",
      "Submissions found :  7\n",
      "Duplicates found :  100\n",
      "ID b0gwio was found.\n",
      "Submissions found :  8\n",
      "Duplicates found :  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID b0gzdj was found.\n",
      "Submissions found :  9\n",
      "Duplicates found :  100\n",
      "ID b0h61w was found.\n",
      "Submissions found :  10\n",
      "Duplicates found :  100\n",
      "ID b0h6w5 was found.\n",
      "Submissions found :  11\n",
      "Duplicates found :  100\n",
      "ID b0h77g was found.\n",
      "Submissions found :  12\n",
      "Duplicates found :  100\n",
      "ID b0h9k7 was found.\n",
      "Submissions found :  13\n",
      "Duplicates found :  100\n",
      "ID b0hd6e was found.\n",
      "Submissions found :  14\n",
      "Duplicates found :  100\n",
      "ID b0hels was found.\n",
      "Submissions found :  15\n",
      "Duplicates found :  100\n",
      "ID b0hh1x was found.\n",
      "Submissions found :  16\n",
      "Duplicates found :  100\n",
      "ID b0hisp was found.\n",
      "Submissions found :  17\n",
      "Duplicates found :  100\n",
      "ID b0ht7q was found.\n",
      "Submissions found :  18\n",
      "Duplicates found :  100\n",
      "ID b0huzb was found.\n",
      "Submissions found :  19\n",
      "Duplicates found :  100\n",
      "ID b0i229 was found.\n",
      "Submissions found :  20\n",
      "Duplicates found :  100\n",
      "ID b0i8az was found.\n",
      "Submissions found :  21\n",
      "Duplicates found :  100\n",
      "ID b0icix was found.\n",
      "Submissions found :  22\n",
      "Duplicates found :  100\n",
      "ID b0iclf was found.\n",
      "Submissions found :  23\n",
      "Duplicates found :  100\n",
      "ID b0id93 was found.\n",
      "Submissions found :  24\n",
      "Duplicates found :  100\n",
      "ID b0idm6 was found.\n",
      "Submissions found :  25\n",
      "Duplicates found :  100\n",
      "ID b0iiil was found.\n",
      "Submissions found :  26\n",
      "Duplicates found :  100\n",
      "ID b0iinj was found.\n",
      "Submissions found :  27\n",
      "Duplicates found :  100\n",
      "ID b0iq0q was found.\n",
      "Submissions found :  28\n",
      "Duplicates found :  100\n",
      "ID b0isq4 was found.\n",
      "Submissions found :  29\n",
      "Duplicates found :  100\n",
      "ID b0iwfi was found.\n",
      "Submissions found :  30\n",
      "Duplicates found :  100\n",
      "ID b0j4zs was found.\n",
      "Submissions found :  31\n",
      "Duplicates found :  100\n",
      "ID b0j6bv was found.\n",
      "Submissions found :  32\n",
      "Duplicates found :  100\n",
      "ID b0j86e was found.\n",
      "Submissions found :  33\n",
      "Duplicates found :  100\n",
      "ID b0j913 was found.\n",
      "Submissions found :  34\n",
      "Duplicates found :  100\n",
      "ID b0je2k was found.\n",
      "Submissions found :  35\n",
      "Duplicates found :  100\n",
      "ID b0jhmm was found.\n",
      "Submissions found :  36\n",
      "Duplicates found :  100\n",
      "ID b0jl85 was found.\n",
      "Submissions found :  37\n",
      "Duplicates found :  100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-45c92c6cf1e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mduplicates_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msubmission\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_CasualConversation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmissions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_submission_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mall_submissions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\praw\\models\\util.py\u001b[0m in \u001b[0;36mstream_generator\u001b[1;34m(function, pause_after, skip_existing, attribute_name)\u001b[0m\n\u001b[0;32m    192\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexponential_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "submissions_found = 0\n",
    "duplicates_found = 0\n",
    "\n",
    "for submission in r_CasualConversation.stream.submissions():\n",
    "    if(all_submission_ids.count(submission.id) == 0):\n",
    "        all_submissions.append(submission)\n",
    "        all_submission_ids.append(submission.id)\n",
    "        print('ID ' + str(submission.id) + ' was found.')\n",
    "        submissions_found += 1\n",
    "    else:\n",
    "        print('Duplicate ID ' + str(submission.id) + ' was found.')\n",
    "        duplicates_found += 1\n",
    "    \n",
    "    print('Submissions found : ', str(submissions_found))\n",
    "    print('Duplicates found : ', str(duplicates_found))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
